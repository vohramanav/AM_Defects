\section{Introduction}
\label{sec:intro}

%1. Motivate the need for a fast surrogate modeling approach: expensive training, large input and output dimensions
%(include applications)
%2. Briefly discuss our approach
%3. Briefly discuss the application: motivate residual stress analysis, reliability analysis is expensive
%4. Key contributions of the paper
%5. Outline

%A surrogate model also referred to as an emulator or a response surface,
%is a widely used and powerful tool that enables a range of applications pertaining to 
%computational science. As the name suggests, a surrogate aims to capture the nature of dependence of a system
%response or a model output on its inputs and parameters. It is typically informed by the underlying physics in the 
%case of a physics-based model or by data in the case of supervised learning~(e.g. neural networks~\cite{Hagan:1996}).
%A reliable surrogate could thus
%be used in lieu of the model for making predictions in a regime where it is validated. 

A surrogate model can offer a significant computational advantage in situations involving intensive
simulations, especially for applications
involving a large number of model evaluations such as uncertainty propagation, sensitivity analysis, parameter
estimation, and optimization. However, constructing a reasonably accurate surrogate itself can be computationally demanding
due to the need to generate training points using the original physics model. 
For instance, estimation of coefficients of a polynomial chaos expansion (PCE)~\cite{Xiu:2002,Ghanem:1991},
can be computationally demanding in large-dimensional applications despite recent development 
of sparse grids~\cite{Gerstner:1998,Ganapathysubramanian:2007} and basis adaptive 
methods~\cite{Blatman:2011,Conrad:2013}. Similarly, in the case of Gaussian 
Process~\cite{Rasmussen:2004} surrogate modeling, computing the inverse of the covariance matrix
becomes challenging in large dimensions. Additionally, the number of tuning parameters associated
with the correlation function also increase with dimensions thereby limiting the applicability of
GPs in large-dimensional applications. 
In the case of support vector machines~(SVMs)~\cite{Cortes:1995} 
and neural networks~(NNs)~\cite{Haykin:1994}, commonly used machine learning models for regression as
well as classification, the accuracy is 
largely dependent on the data used to train them. Hence, their applicability is limited 
in situations involving sparse and noisy training data. 
%In addition to the aforementioned `algebraic' surrogate models
%(PCE, GP, SVMs, NNs), probabilistic surrogate models such as Bayesian networks~(BN) have been 
%explored to approximate the joint probability density function~(PDF) of the input and the output variables. While BN provides
%a robust framework for uncertainty quantification,  estimating the joint PDF typically requires a large amount of
%computational and experimental resources.  Liang and Mahadevan recently demonstrated
%the use of a copula-based sampling technique coupled with principal component analysis~(PCA)
% for dimensionality reduction in order to
%reduce the underlying effort pertaining to posterior evaluation using a BN in a multidisciplinary setting~\cite{Liang:2016}. 

Traditional methods for surrogate modeling have mainly focused on gains in efficiency by reducing the
dimensionality in either the input space or the output space. Dimension reduction in the input space
aims to reduce the training effort using sparse grids~\cite{Petvipusit:2014,Elsheikh:2014,Zhang:2013,Ma:2009},
projection to a sparse orthogonal basis~(e.g. PCE, proper orthogonal decomposition~(POD),
Karhunen-Loeve Expansion)~\cite{Wang:2005,Galbally:2010,Marzouk:2009} or a combination of both 
strategies~(e.g. sparse pseudospectral approximation)~\cite{Constantine:2012,Winokur:2013,Conrad:2013,Vohra:2017}.
On the other hand, dimension reduction in the output space has been accomplished using spectral decomposition 
to capture dominant modes or principal directions in the output data represented in the form of a 
matrix~(e.g. singular value decomposition~(SVD) in the case of PCA)~\cite{Hombal:2013,Nath:2017,Borgman:1976,Davis:1983}.
Additionally, methods such as co-kriging~\cite{Myers:1982} have also been used for output dimension reduction.  
However, it must be noted
that co-kriging approaches can be computationally demanding for large-dimensional field quantities of interest~\cite{Gogu:2013}. 

In this work, we present a novel approach aimed at combining dimension reduction in the output space with
dimension reduction in the input space. Specifically, PCA is exploited to extract key features in the
output field quantity of interest. Then, we discover a 
low-dimensional structure in the relationship between representative features of the output and the set of inputs using
the active
subspace methodology~\cite{Constantine:2015}. The proposed methodology is
referred to as the PCAS method in this work as it combines principal components~(PC) with active subspaces~(AS).
Thus, the proposed methodology aims to \textit{compound} computational gains by constructing a low-dimensional
relationship between uncertain variables in the input space and representative features in a low-dimensional
output space. The proposed methodology is applied to a multiphysics problem wherein a
surrogate is constructed for an expensive thermo-mechanical finite element model~(FEM) for the purpose of reliability
analysis of a mechanical component fabricated using an additive manufacturing process. Tremendous scope
for computational gains are observed as the resulting surrogate, constructed using a sparse set of realizations
of the expensive physics model is shown to reconstruct the field quantity of interest~(residual stress)
with reasonable accuracy. Our findings motivate the use of the PCAS method for other applications involving
a high-dimensional input and output.     

Residual stress develops during the manufacturing process due to the presence of steep thermal gradients as
well as physical constraints in the part which adversely affect its mechanical properties, geometry, and 
shape~\cite{Withers:2001,Mercelis:2006,Hofmann:2014}. 
In fact, residual stress in addition to porosity is one of the main reasons for 
part failure~\cite{Kim:2018}. The presence of residual stress in an AM part has significantly 
inhibited rapid certification as well as standardization of the certification process
due to post processing involving machining and heat treatment~\cite{Shiomi:2004}.
Several recent investigations~\cite{Vastola:2016,Hodge:2016,Williams:2018}
have focused on developing thermo-mechanical
models to better understand the development of residual stress and optimize the microstructure as well as
the process control parameters accordingly. However, since the simulations are intensive and models require a 
large amount of calibration data, the progress has so far been limited by the availability
of computational and experimental resources. Through this study, we aim to demonstrate an effective strategy
based on surrogate modeling that could accelerate material selection, microstructure design, and
process control and optimization for controlling the evolution residual stress during additive manufacturing. 

Residual stress in an AM part is computed using a finite element thermo-mechanical model in Abaqus in this work. 
More specifically, the FEM includes a thermal model that simulates the thermal response of the
part. Part thermal response is then used as an input to a mechanical model that predicts residual stress at the end
of a cooling phase. For a given set of process conditions and material properties, the thermal model requires
approximately 20 minutes to generate the temperature field and the mechanical model takes approximately 10
minutes to estimate the residual stress in the part. Therefore, one realization of the output field of interest
using the FEM requires approximately 30 minutes. In order to perform reliability analysis using
sampling techniques, $\mathcal{O}(10^4-10^5)$ realizations are typically required for reasonable accuracy.  
Therefore, it is not practical
to rely on the FEM for this purpose. Additionally, conventional approaches for surrogate
modeling would require a large amount of computational resources for the purpose of training as discussed earlier.
 A random field approximation is a possibility for
output dimension reduction. However, such an approximation could potentially introduce large errors in the  
representation of the non-stationary output field. Instead, we aim to exploit the structure in the output data 
by identifying important 
directions or principal components in the field. This approach allows us to select an optimal number of 
features required to re-construct the field with reasonable accuracy and computational effort. 

The main highlights of this paper are as follows: (1) A computationally efficient approach is developed
for constructing a surrogate model for problems where both input and output are high-dimensional.
In particular, the output is a field quantity. 
(2) A finite element model is developed to simulate residual stress in an additively manufactured part
at the end of a single scan of the laser beam in an EBM process. (3) The surrogate model is used to perform a global
sensitivity analysis~(GSA) to assess relative importance of the material properties and the process control parameters
in the context of residual stress. (4) Finally, the surrogate model is used for the purpose of reliability analysis by estimating the
probability that residual stress in the part exceeds a certain threshold.

The remainder of this paper is organized as follows: Section~\ref{sec:method} outlines the proposed methodology for
constructing the surrogate model including a brief background on the active subspace methodology used in this work.
Section~\ref{sec:model} details the finite element model used to generate stress data for building the surrogate model.
Section~\ref{sec:results} provides numerical results and discussion pertaining to the implementation of the methodology 
for surrogate construction, hotspot identification, GSA, and 
reliability analysis of the AM product. 
Finally, we summarize this study in Section~\ref{sec:conc}. 



